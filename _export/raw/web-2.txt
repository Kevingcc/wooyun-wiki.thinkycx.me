#WEB应用收集

WEB应用的收集是建立在IP、域名以及端口所收集到的数据之上的。

每一个IP及域名对外开放的端口都可能搭建了WEB服务。

除此之外，还有以下方式扩大针对WEB应用的收集：

###1、目录及文件扫描

----

针对开放WEB服务的端口进行常见的敏感目录以及文件扫描，这些对以后的突破都可能产生至关重要的作用。

这些敏感的目录猪猪侠已经写过相关工具，工具介绍以及设计思想可以在社区中看到：[[http://zone.wooyun.org/content/19523|动态多线程敏感信息泄露检测工具--weakfilescan]].

###2、网络搜索

----

可以在github上通过一些关键字搜索相关企业的代码，如果该企业在github上有放公开的代码，那么可以搜索到对其代码进行分析，有的甚至会存在一些敏感账号的用户名密码，例如邮箱，svn，ftp等。

可以看社区的讨论：[[http://zone.wooyun.org/content/12855|如何从github上找漏洞]]。

还可以针对一些页面的历史信息信息收集：

如果一些页面已经被修改，Google与百度之前爬过该页面，那么可以通过Google与百度的缓存查看页面原来的样子。

同时[[http://archive.org/web|时光倒流机]]这个网站上会保存一个网站的很多历史页面，如果有记录的话，可以看到一个网站之前采用的WEB应用。
